# Architecture Explanation

## ğŸ” Why Three Separate Files?

Each file has a **single, specific responsibility**. This is called **"Separation of Concerns"** - a key software engineering principle.

---

## ğŸ“Š The Pipeline Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DOCUMENT PROCESSOR                        â”‚
â”‚                  (document_processor.py)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  This is the ORCHESTRATOR - it coordinates           â”‚   â”‚
â”‚  â”‚  the other two modules                                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â”‚ uses
                          â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                                 â”‚
        â–¼                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DOCUMENT LOADER  â”‚          â”‚  VECTOR STORE    â”‚
â”‚                  â”‚          â”‚                  â”‚
â”‚ document_loader  â”‚          â”‚ vector_store.py  â”‚
â”‚      .py         â”‚          â”‚                  â”‚
â”‚                  â”‚          â”‚                  â”‚
â”‚ Job:             â”‚          â”‚ Job:             â”‚
â”‚ â€¢ Read files     â”‚          â”‚ â€¢ Store          â”‚
â”‚ â€¢ Parse PDF/TXT  â”‚          â”‚   embeddings     â”‚
â”‚ â€¢ Split text     â”‚          â”‚ â€¢ Search         â”‚
â”‚   into chunks    â”‚          â”‚   similar docs   â”‚
â”‚                  â”‚          â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                                 â”‚
        â”‚ chunks                          â”‚ embeddings
        â”‚                                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  ChromaDB     â”‚
            â”‚  Database     â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ File Responsibilities

### 1ï¸âƒ£ `document_loader.py` - **File Reader & Text Processor**
**What it does:**
- âœ… Reads PDF, TXT, DOCX files from `uploaded_documents/` folder
- âœ… Extracts text from files
- âœ… Splits text into smaller chunks (for embedding)
- âŒ **Does NOT** handle embeddings
- âŒ **Does NOT** handle database storage

**Think of it as:** A librarian who reads books and prepares pages

---

### 2ï¸âƒ£ `vector_store.py` - **Database Manager**
**What it does:**
- âœ… Takes text chunks (from DocumentLoader)
- âœ… Converts them to embeddings (using Google Gemini embeddings)
- âœ… Stores embeddings in ChromaDB
- âœ… Searches for similar documents
- âŒ **Does NOT** read files
- âŒ **Does NOT** parse PDFs

**Think of it as:** A database that stores and searches documents

---

### 3ï¸âƒ£ `document_processor.py` - **Orchestrator (The Boss)**
**What it does:**
- âœ… **Uses** DocumentLoader to get chunks
- âœ… **Uses** VectorStore to store chunks
- âœ… Coordinates the entire pipeline
- âœ… Provides a simple interface: `process_documents()`

**Think of it as:** The manager who coordinates the librarian and database

---

## ğŸ”„ How They Work Together

### Step-by-Step Flow:

```python
# 1. You call the processor
processor = DocumentProcessor()

# 2. Processor uses DocumentLoader
chunks = processor.document_loader.process_all()
#    â†“
#    DocumentLoader reads files and creates chunks
#    Returns: List of text chunks

# 3. Processor uses VectorStore
processor.vector_store.add_documents(chunks)
#    â†“
#    VectorStore converts chunks to embeddings
#    Stores them in ChromaDB

# 4. Done! Documents are now searchable
```

---

## ğŸ’¡ Why This Design?

### âœ… **Benefits:**

1. **Modularity**: Each file does one thing well
2. **Reusability**: You can use DocumentLoader without VectorStore
3. **Testability**: Test each component separately
4. **Maintainability**: Fix bugs in one place
5. **Flexibility**: Swap components (e.g., use different vector DB)

### âŒ **Without Separation:**

If everything was in one file:
- Hard to test
- Hard to reuse
- Hard to maintain
- Can't swap components

---

## ğŸ¯ Real-World Analogy

**Restaurant Kitchen:**

- **DocumentLoader** = Prep Cook (cuts vegetables, prepares ingredients)
- **VectorStore** = Head Chef (cooks, stores food)
- **DocumentProcessor** = Restaurant Manager (coordinates everything)

Each has a specific job, but they work together!

---

## ğŸ”§ When to Use Each File Directly

### Use `DocumentLoader` directly when:
- You just want to read and chunk documents
- You don't need to store embeddings
- You're testing document parsing

### Use `VectorStore` directly when:
- You already have text chunks
- You just want to search existing documents
- You're testing search functionality

### Use `DocumentProcessor` when:
- You want the complete pipeline (most common case)
- You're building the application
- You want the simplest interface

### Use `RAGPipeline` when:
- You want to ask questions about your documents
- You've already processed documents
- You want answers with source citations

---

## ğŸ“ Example: Direct Usage

```python
# Using DocumentLoader alone
from src.document_loader import DocumentLoader
loader = DocumentLoader()
chunks = loader.process_all()
# Now you have chunks, but they're not stored yet

# Using VectorStore alone
from src.vector_store import VectorStore
store = VectorStore()
# Assume chunks already exist
store.add_documents(chunks)
results = store.similarity_search("machine learning")

# Using DocumentProcessor (easiest)
from src.document_processor import DocumentProcessor
processor = DocumentProcessor()
processor.process_documents()  # Does everything!

# Using RAGPipeline (for questions)
from src.rag_pipeline import RAGPipeline
rag = RAGPipeline()
result = rag.answer_question("What is machine learning?")
print(result['answer'])
```

---

---

## 4ï¸âƒ£ `rag_pipeline.py` - **Question-Answering System**

**What it does:**
- âœ… Retrieves relevant document chunks using VectorStore
- âœ… Builds context from retrieved chunks
- âœ… Generates answers using Google Gemini LLM (via LangChain wrapper)
- âœ… Returns answers with source citations
- âŒ **Does NOT** process new documents
- âŒ **Does NOT** modify the vector store

**Think of it as:** A research assistant that answers questions using your document collection

**Technical Details:**
- Uses `gemini-2.5-flash` model
- Uses LangChain's `ChatGoogleGenerativeAI` wrapper
- Retrieves top-k similar documents (default: 5)
- Generates answers based on retrieved context

---

## âœ… Summary

| File | Responsibility | Input | Output |
|------|---------------|-------|--------|
| `document_loader.py` | Read & chunk files | Files in folder | Text chunks |
| `vector_store.py` | Store & search | Text chunks | Embeddings in DB |
| `document_processor.py` | Orchestrate | Nothing | Everything! |
| `rag_pipeline.py` | Answer questions | Questions | Answers + sources |

**They work together, but each has a clear, separate job!**

---

## ğŸ”„ Complete Pipeline Flow

```
1. Document Processing (document_processor.py)
   â”œâ”€â†’ DocumentLoader: Reads files â†’ Creates chunks
   â””â”€â†’ VectorStore: Stores chunks â†’ Creates embeddings

2. Question Answering (rag_pipeline.py)
   â”œâ”€â†’ VectorStore: Searches for similar chunks
   â”œâ”€â†’ Context Building: Combines retrieved chunks
   â””â”€â†’ LLM (LangChain): Generates answer from context
```

